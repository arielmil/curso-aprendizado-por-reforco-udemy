{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f05511",
   "metadata": {},
   "source": [
    "Neste notebook será criado um perceptron de uma camada para aprender a função AND.\n",
    "\n",
    "Tudo será feito manualmente usando o pytorch para operações de tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a46508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff61d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9177000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converte X para um tensor para o pytorch\n",
    "X_t = torch.from_numpy(X).double()\n",
    "\n",
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0b8315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "159022fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_t = torch.from_numpy(Y).double()\n",
    "\n",
    "Y_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facbb356",
   "metadata": {},
   "source": [
    "Configura-se o pytorch para usar acelerção em GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b9651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78dbfcb",
   "metadata": {},
   "source": [
    "Com o dataset pronto, começa-se a definição da rede neural:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4c1dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.zeros((2, 1), dtype=torch.float64)\n",
    "\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a4610b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma = torch.matmul(X_t, W)\n",
    "\n",
    "soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb608c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retorna 0 se x < 1, ou 1 se x >= 1.\n",
    "def step(x):\n",
    "    x = torch.as_tensor(x, dtype=torch.float64)  # garante tensor\n",
    "    return torch.ge(x, 1).to(torch.float64)\n",
    "\n",
    "step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a260b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ativacao = step(soma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc8a26df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erro = Y_t - ativacao\n",
    "\n",
    "erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bff5290f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1.],\n",
       "        [0., 1., 0., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transposed = X_t.t()\n",
    "\n",
    "X_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b345b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = torch.matmul(X_transposed, erro)\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da90e578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000],\n",
       "        [0.1000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "treinamento = delta * learning_rate\n",
    "\n",
    "treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0b6032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000],\n",
       "        [0.1000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momento = 1\n",
    "treinamento_ = W * momento + treinamento\n",
    "\n",
    "treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27c286c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000],\n",
       "        [0.1000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = treinamento\n",
    "\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365487cb",
   "metadata": {},
   "source": [
    "Inicio do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "334f8936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 1  Erro:  1.0\n",
      "Epoca: 2  Erro:  1.0\n",
      "Epoca: 3  Erro:  1.0\n",
      "Epoca: 4  Erro:  1.0\n",
      "Epoca: 5  Erro:  0.0\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "learning_rate = 0.1\n",
    "momento = 1\n",
    "\n",
    "for i in range(15):\n",
    "    epoch += 1\n",
    "    \n",
    "    soma = torch.matmul(X_t, W)\n",
    "    ativacao = step(soma)\n",
    "    erro = Y_t - ativacao\n",
    "    X_transposed = X_t.t()\n",
    "    delta = torch.matmul(X_transposed, erro)\n",
    "    treinamento = W * momento + delta * learning_rate\n",
    "    W = treinamento\n",
    "\n",
    "    \n",
    "    errors_sum = torch.sum(erro).item()\n",
    "    print('Epoca:', epoch, ' Erro: ', errors_sum)\n",
    "\n",
    "    if errors_sum == 0.0:\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3d30a",
   "metadata": {},
   "source": [
    "Teste da rede neural:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e162662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_sum = torch.matmul(X_t, W)\n",
    "teste_ativacao = step(teste_sum)\n",
    "\n",
    "teste_ativacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2da7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x, w):\n",
    "    teste_sum = torch.matmul(x, w)\n",
    "    return step(teste_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "512d5e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A entrada: [0. 0.], tem output: [0.]\n",
      "A entrada: [0. 1.], tem output: [0.]\n",
      "A entrada: [1. 0.], tem output: [0.]\n",
      "A entrada: [1. 1.], tem output: [1.]\n"
     ]
    }
   ],
   "source": [
    "for value in X_t:\n",
    "    print(\"A entrada: \" + str (value.numpy()) + \", tem output: \" + str(perceptron(value, W).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e38906",
   "metadata": {},
   "source": [
    "Agora farei o mesmo processo, porém usando a biblioteca pytorch para fazer tudo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53636afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Terá apenas duas camadas, uma com in_features neuronios de entrada e outra 1 neuronio de saída.\n",
    "        self.linear = nn.Linear(in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)                     # depois aplicamos função de ativação se quiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8121320",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Carrega X_t e Y_t no device (GPU)\n",
    "X_t = torch.from_numpy(X).float().to(device)          # (N, in_features)\n",
    "Y_t = torch.from_numpy(Y).float().view(-1, 1).to(device)  #.view(-1, 1) converte o tensor para (N, 1)\n",
    "\n",
    "model = Perceptron(in_features=X_t.shape[1]).to(device)\n",
    "\n",
    "# Para função loss\n",
    "criterion = nn.BCEWithLogitsLoss()    # para classificação binária (0/1)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9358ffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6322481632232666\n",
      "2 0.6296948194503784\n",
      "3 0.6271647214889526\n",
      "4 0.6246574521064758\n",
      "5 0.6221727132797241\n",
      "6 0.6197099089622498\n",
      "7 0.6172687411308289\n",
      "8 0.614848792552948\n",
      "9 0.6124497652053833\n",
      "10 0.6100713014602661\n",
      "11 0.6077129244804382\n",
      "12 0.6053743958473206\n",
      "13 0.603055477142334\n",
      "14 0.6007556319236755\n",
      "15 0.5984748005867004\n",
      "16 0.5962125062942505\n",
      "17 0.5939686894416809\n",
      "18 0.5917428135871887\n",
      "19 0.5895347595214844\n",
      "20 0.5873443484306335\n",
      "21 0.5851711630821228\n",
      "22 0.5830151438713074\n",
      "23 0.5808759331703186\n",
      "24 0.5787532925605774\n",
      "25 0.5766471028327942\n",
      "26 0.5745570659637451\n",
      "27 0.5724830627441406\n",
      "28 0.5704247951507568\n",
      "29 0.5683821439743042\n",
      "30 0.5663548707962036\n",
      "31 0.5643427968025208\n",
      "32 0.5623457431793213\n",
      "33 0.5603636503219604\n",
      "34 0.55839604139328\n",
      "35 0.5564430952072144\n",
      "36 0.55450439453125\n",
      "37 0.5525799989700317\n",
      "38 0.5506695508956909\n",
      "39 0.5487729907035828\n",
      "40 0.5468901991844177\n",
      "41 0.5450209379196167\n",
      "42 0.5431650876998901\n",
      "43 0.5413225293159485\n",
      "44 0.539493203163147\n",
      "45 0.5376767516136169\n",
      "46 0.5358732342720032\n",
      "47 0.5340824127197266\n",
      "48 0.5323042869567871\n",
      "49 0.5305386781692505\n",
      "50 0.5287853479385376\n",
      "51 0.5270442366600037\n",
      "52 0.5253152847290039\n",
      "53 0.523598313331604\n",
      "54 0.5218932032585144\n",
      "55 0.5201997756958008\n",
      "56 0.5185181498527527\n",
      "57 0.5168479681015015\n",
      "58 0.5151892304420471\n",
      "59 0.5135417580604553\n",
      "60 0.5119055509567261\n",
      "61 0.5102803707122803\n",
      "62 0.5086661577224731\n",
      "63 0.5070629119873047\n",
      "64 0.5054703950881958\n",
      "65 0.5038885474205017\n",
      "66 0.5023173093795776\n",
      "67 0.5007565021514893\n",
      "68 0.49920618534088135\n",
      "69 0.49766606092453003\n",
      "70 0.4961361289024353\n",
      "71 0.49461629986763\n",
      "72 0.49310654401779175\n",
      "73 0.49160659313201904\n",
      "74 0.49011653661727905\n",
      "75 0.48863619565963745\n",
      "76 0.48716551065444946\n",
      "77 0.48570430278778076\n",
      "78 0.4842526316642761\n",
      "79 0.4828103482723236\n",
      "80 0.48137736320495605\n",
      "81 0.4799535870552063\n",
      "82 0.4785388708114624\n",
      "83 0.47713324427604675\n",
      "84 0.4757365882396698\n",
      "85 0.47434884309768677\n",
      "86 0.4729698896408081\n",
      "87 0.47159960865974426\n",
      "88 0.4702380299568176\n",
      "89 0.46888506412506104\n",
      "90 0.46754053235054016\n",
      "91 0.46620437502861023\n",
      "92 0.464876651763916\n",
      "93 0.4635571539402008\n",
      "94 0.4622458517551422\n",
      "95 0.46094271540641785\n",
      "96 0.45964759588241577\n",
      "97 0.4583604633808136\n",
      "98 0.45708125829696655\n",
      "99 0.45580992102622986\n",
      "100 0.4545462727546692\n",
      "101 0.4532904028892517\n",
      "102 0.45204222202301025\n",
      "103 0.4508014917373657\n",
      "104 0.44956839084625244\n",
      "105 0.4483426511287689\n",
      "106 0.44712433218955994\n",
      "107 0.44591331481933594\n",
      "108 0.44470953941345215\n",
      "109 0.4435129761695862\n",
      "110 0.4423235058784485\n",
      "111 0.44114112854003906\n",
      "112 0.43996575474739075\n",
      "113 0.4387972950935364\n",
      "114 0.43763574957847595\n",
      "115 0.4364810287952423\n",
      "116 0.4353330731391907\n",
      "117 0.43419182300567627\n",
      "118 0.4330572187900543\n",
      "119 0.43192923069000244\n",
      "120 0.43080776929855347\n",
      "121 0.4296928346157074\n",
      "122 0.4285842776298523\n",
      "123 0.42748212814331055\n",
      "124 0.426386296749115\n",
      "125 0.4252966642379761\n",
      "126 0.42421334981918335\n",
      "127 0.4231361150741577\n",
      "128 0.4220650792121887\n",
      "129 0.42100000381469727\n",
      "130 0.4199410676956177\n",
      "131 0.4188879728317261\n",
      "132 0.4178408980369568\n",
      "133 0.4167996048927307\n",
      "134 0.4157641530036926\n",
      "135 0.41473448276519775\n",
      "136 0.41371050477027893\n",
      "137 0.41269218921661377\n",
      "138 0.4116794764995575\n",
      "139 0.4106723666191101\n",
      "140 0.4096708297729492\n",
      "141 0.4086747467517853\n",
      "142 0.4076841473579407\n",
      "143 0.40669888257980347\n",
      "144 0.40571898221969604\n",
      "145 0.4047444462776184\n",
      "146 0.40377509593963623\n",
      "147 0.4028110206127167\n",
      "148 0.4018521308898926\n",
      "149 0.4008983373641968\n",
      "150 0.39994966983795166\n",
      "151 0.39900606870651245\n",
      "152 0.3980674743652344\n",
      "153 0.39713382720947266\n",
      "154 0.39620518684387207\n",
      "155 0.3952814042568207\n",
      "156 0.39436253905296326\n",
      "157 0.3934484124183655\n",
      "158 0.39253902435302734\n",
      "159 0.391634464263916\n",
      "160 0.39073458313941956\n",
      "161 0.38983938097953796\n",
      "162 0.38894879817962646\n",
      "163 0.38806283473968506\n",
      "164 0.3871814012527466\n",
      "165 0.3863045275211334\n",
      "166 0.3854321241378784\n",
      "167 0.3845641613006592\n",
      "168 0.3837006092071533\n",
      "169 0.38284143805503845\n",
      "170 0.3819866180419922\n",
      "171 0.3811361789703369\n",
      "172 0.3802899122238159\n",
      "173 0.3794479966163635\n",
      "174 0.37861019372940063\n",
      "175 0.3777766525745392\n",
      "176 0.376947283744812\n",
      "177 0.37612199783325195\n",
      "178 0.3753007650375366\n",
      "179 0.3744836151599884\n",
      "180 0.37367045879364014\n",
      "181 0.3728613555431366\n",
      "182 0.372056245803833\n",
      "183 0.37125498056411743\n",
      "184 0.3704577088356018\n",
      "185 0.3696642220020294\n",
      "186 0.3688746690750122\n",
      "187 0.36808884143829346\n",
      "188 0.3673068881034851\n",
      "189 0.36652871966362\n",
      "190 0.3657541871070862\n",
      "191 0.3649834394454956\n",
      "192 0.36421626806259155\n",
      "193 0.36345285177230835\n",
      "194 0.3626929819583893\n",
      "195 0.3619367778301239\n",
      "196 0.36118412017822266\n",
      "197 0.3604349195957184\n",
      "198 0.3596893548965454\n",
      "199 0.3589472472667694\n",
      "200 0.3582085967063904\n",
      "201 0.35747334361076355\n",
      "202 0.3567415475845337\n",
      "203 0.35601314902305603\n",
      "204 0.3552881181240082\n",
      "205 0.35456642508506775\n",
      "206 0.35384809970855713\n",
      "207 0.3531329035758972\n",
      "208 0.35242119431495667\n",
      "209 0.3517126142978668\n",
      "210 0.35100725293159485\n",
      "211 0.35030511021614075\n",
      "212 0.34960609674453735\n",
      "213 0.34891030192375183\n",
      "214 0.3482176661491394\n",
      "215 0.34752804040908813\n",
      "216 0.34684157371520996\n",
      "217 0.3461581766605377\n",
      "218 0.34547775983810425\n",
      "219 0.3448004722595215\n",
      "220 0.3441261053085327\n",
      "221 0.3434547185897827\n",
      "222 0.34278634190559387\n",
      "223 0.34212085604667664\n",
      "224 0.3414583206176758\n",
      "225 0.34079867601394653\n",
      "226 0.3401418924331665\n",
      "227 0.3394879102706909\n",
      "228 0.3388368785381317\n",
      "229 0.33818864822387695\n",
      "230 0.33754315972328186\n",
      "231 0.336900532245636\n",
      "232 0.33626052737236023\n",
      "233 0.3356234133243561\n",
      "234 0.33498892188072205\n",
      "235 0.33435726165771484\n",
      "236 0.3337281346321106\n",
      "237 0.333101749420166\n",
      "238 0.33247801661491394\n",
      "239 0.331856906414032\n",
      "240 0.33123838901519775\n",
      "241 0.3306225538253784\n",
      "242 0.33000922203063965\n",
      "243 0.3293984532356262\n",
      "244 0.32879024744033813\n",
      "245 0.3281846046447754\n",
      "246 0.32758140563964844\n",
      "247 0.3269807696342468\n",
      "248 0.3263825476169586\n",
      "249 0.325786828994751\n",
      "250 0.3251935839653015\n",
      "251 0.3246026933193207\n",
      "252 0.3240143060684204\n",
      "253 0.3234281539916992\n",
      "254 0.32284456491470337\n",
      "255 0.32226330041885376\n",
      "256 0.3216843903064728\n",
      "257 0.32110777497291565\n",
      "258 0.3205334544181824\n",
      "259 0.3199614882469177\n",
      "260 0.31939178705215454\n",
      "261 0.3188243806362152\n",
      "262 0.31825923919677734\n",
      "263 0.31769630312919617\n",
      "264 0.31713563203811646\n",
      "265 0.3165772259235382\n",
      "266 0.3160209655761719\n",
      "267 0.3154669404029846\n",
      "268 0.3149150311946869\n",
      "269 0.31436529755592346\n",
      "270 0.31381773948669434\n",
      "271 0.3132723569869995\n",
      "272 0.31272900104522705\n",
      "273 0.3121878504753113\n",
      "274 0.31164878606796265\n",
      "275 0.3111117482185364\n",
      "276 0.31057673692703247\n",
      "277 0.3100438416004181\n",
      "278 0.30951303243637085\n",
      "279 0.3089842200279236\n",
      "280 0.3084574043750763\n",
      "281 0.30793261528015137\n",
      "282 0.3074098229408264\n",
      "283 0.30688899755477905\n",
      "284 0.30637016892433167\n",
      "285 0.30585330724716187\n",
      "286 0.3053382933139801\n",
      "287 0.3048253059387207\n",
      "288 0.3043142259120941\n",
      "289 0.30380502343177795\n",
      "290 0.303297758102417\n",
      "291 0.30279242992401123\n",
      "292 0.30228888988494873\n",
      "293 0.30178719758987427\n",
      "294 0.301287442445755\n",
      "295 0.300789475440979\n",
      "296 0.30029335618019104\n",
      "297 0.29979902505874634\n",
      "298 0.29930657148361206\n",
      "299 0.29881584644317627\n",
      "300 0.29832693934440613\n",
      "301 0.29783985018730164\n",
      "302 0.29735448956489563\n",
      "303 0.2968708872795105\n",
      "304 0.29638904333114624\n",
      "305 0.29590892791748047\n",
      "306 0.2954304814338684\n",
      "307 0.2949538230895996\n",
      "308 0.29447880387306213\n",
      "309 0.2940055727958679\n",
      "310 0.29353395104408264\n",
      "311 0.29306402802467346\n",
      "312 0.292595773935318\n",
      "313 0.2921292185783386\n",
      "314 0.2916642427444458\n",
      "315 0.2912009358406067\n",
      "316 0.2907392382621765\n",
      "317 0.29027923941612244\n",
      "318 0.28982076048851013\n",
      "319 0.28936395049095154\n",
      "320 0.28890860080718994\n",
      "321 0.28845494985580444\n",
      "322 0.2880029082298279\n",
      "323 0.2875523269176483\n",
      "324 0.2871033549308777\n",
      "325 0.28665590286254883\n",
      "326 0.28621000051498413\n",
      "327 0.285765677690506\n",
      "328 0.28532275557518005\n",
      "329 0.2848814129829407\n",
      "330 0.28444162011146545\n",
      "331 0.2840033173561096\n",
      "332 0.28356650471687317\n",
      "333 0.28313112258911133\n",
      "334 0.2826971411705017\n",
      "335 0.28226470947265625\n",
      "336 0.28183379769325256\n",
      "337 0.2814042568206787\n",
      "338 0.28097617626190186\n",
      "339 0.28054946660995483\n",
      "340 0.2801242470741272\n",
      "341 0.27970045804977417\n",
      "342 0.279278039932251\n",
      "343 0.2788569927215576\n",
      "344 0.27843737602233887\n",
      "345 0.27801916003227234\n",
      "346 0.27760231494903564\n",
      "347 0.27718687057495117\n",
      "348 0.27677273750305176\n",
      "349 0.2763599753379822\n",
      "350 0.27594849467277527\n",
      "351 0.27553844451904297\n",
      "352 0.2751297354698181\n",
      "353 0.2747223377227783\n",
      "354 0.2743161916732788\n",
      "355 0.27391138672828674\n",
      "356 0.2735080122947693\n",
      "357 0.27310580015182495\n",
      "358 0.27270492911338806\n",
      "359 0.27230527997016907\n",
      "360 0.2719070315361023\n",
      "361 0.27150994539260864\n",
      "362 0.27111420035362244\n",
      "363 0.27071964740753174\n",
      "364 0.2703263759613037\n",
      "365 0.2699342966079712\n",
      "366 0.2695435583591461\n",
      "367 0.26915404200553894\n",
      "368 0.2687656879425049\n",
      "369 0.2683785855770111\n",
      "370 0.2679927349090576\n",
      "371 0.26760798692703247\n",
      "372 0.2672245502471924\n",
      "373 0.266842246055603\n",
      "374 0.2664611339569092\n",
      "375 0.2660812735557556\n",
      "376 0.265702486038208\n",
      "377 0.2653249502182007\n",
      "378 0.26494860649108887\n",
      "379 0.264573335647583\n",
      "380 0.26419925689697266\n",
      "381 0.26382631063461304\n",
      "382 0.26345449686050415\n",
      "383 0.26308387517929077\n",
      "384 0.26271432638168335\n",
      "385 0.26234596967697144\n",
      "386 0.2619786560535431\n",
      "387 0.26161253452301025\n",
      "388 0.2612473964691162\n",
      "389 0.26088351011276245\n",
      "390 0.2605206072330475\n",
      "391 0.26015886664390564\n",
      "392 0.259798139333725\n",
      "393 0.2594386041164398\n",
      "394 0.25908005237579346\n",
      "395 0.25872260332107544\n",
      "396 0.25836625695228577\n",
      "397 0.2580109238624573\n",
      "398 0.25765660405158997\n",
      "399 0.2573034465312958\n",
      "400 0.256951242685318\n",
      "401 0.25660014152526855\n",
      "402 0.2562499940395355\n",
      "403 0.25590091943740845\n",
      "404 0.25555291771888733\n",
      "405 0.25520583987236023\n",
      "406 0.2548598647117615\n",
      "407 0.2545148432254791\n",
      "408 0.25417089462280273\n",
      "409 0.25382786989212036\n",
      "410 0.25348591804504395\n",
      "411 0.25314491987228394\n",
      "412 0.25280484557151794\n",
      "413 0.25246578454971313\n",
      "414 0.2521277666091919\n",
      "415 0.2517906427383423\n",
      "416 0.25145453214645386\n",
      "417 0.25111937522888184\n",
      "418 0.2507852017879486\n",
      "419 0.2504519522190094\n",
      "420 0.250119686126709\n",
      "421 0.2497882843017578\n",
      "422 0.2494579404592514\n",
      "423 0.24912849068641663\n",
      "424 0.24879992008209229\n",
      "425 0.24847227334976196\n",
      "426 0.24814565479755402\n",
      "427 0.24781988561153412\n",
      "428 0.24749502539634705\n",
      "429 0.247171089053154\n",
      "430 0.24684807658195496\n",
      "431 0.24652594327926636\n",
      "432 0.2462046891450882\n",
      "433 0.24588441848754883\n",
      "434 0.24556493759155273\n",
      "435 0.24524641036987305\n",
      "436 0.24492870271205902\n",
      "437 0.2446119487285614\n",
      "438 0.24429601430892944\n",
      "439 0.24398091435432434\n",
      "440 0.24366673827171326\n",
      "441 0.2433534562587738\n",
      "442 0.2430410385131836\n",
      "443 0.24272942543029785\n",
      "444 0.24241863191127777\n",
      "445 0.24210870265960693\n",
      "446 0.24179968237876892\n",
      "447 0.24149146676063538\n",
      "448 0.24118399620056152\n",
      "449 0.24087749421596527\n",
      "450 0.2405717819929123\n",
      "451 0.2402668297290802\n",
      "452 0.23996280133724213\n",
      "453 0.23965954780578613\n",
      "454 0.2393571138381958\n",
      "455 0.23905551433563232\n",
      "456 0.23875465989112854\n",
      "457 0.238454669713974\n",
      "458 0.23815539479255676\n",
      "459 0.23785699903964996\n",
      "460 0.23755937814712524\n",
      "461 0.23726250231266022\n",
      "462 0.23696646094322205\n",
      "463 0.23667123913764954\n",
      "464 0.23637673258781433\n",
      "465 0.2360830307006836\n",
      "466 0.23579004406929016\n",
      "467 0.23549789190292358\n",
      "468 0.2352064698934555\n",
      "469 0.2349158525466919\n",
      "470 0.2346259355545044\n",
      "471 0.23433685302734375\n",
      "472 0.23404845595359802\n",
      "473 0.23376083374023438\n",
      "474 0.23347392678260803\n",
      "475 0.23318776488304138\n",
      "476 0.2329024076461792\n",
      "477 0.2326177954673767\n",
      "478 0.23233386874198914\n",
      "479 0.23205068707466125\n",
      "480 0.23176825046539307\n",
      "481 0.2314864993095398\n",
      "482 0.23120546340942383\n",
      "483 0.23092523217201233\n",
      "484 0.23064562678337097\n",
      "485 0.23036673665046692\n",
      "486 0.23008859157562256\n",
      "487 0.22981113195419312\n",
      "488 0.22953444719314575\n",
      "489 0.22925838828086853\n",
      "490 0.228983074426651\n",
      "491 0.22870837152004242\n",
      "492 0.2284344732761383\n",
      "493 0.22816121578216553\n",
      "494 0.22788861393928528\n",
      "495 0.22761675715446472\n",
      "496 0.2273455411195755\n",
      "497 0.22707504034042358\n",
      "498 0.2268051654100418\n",
      "499 0.22653593122959137\n",
      "500 0.22626745700836182\n",
      "501 0.2259996384382248\n",
      "502 0.2257324755191803\n",
      "503 0.22546595335006714\n",
      "504 0.2252001315355301\n",
      "505 0.22493496537208557\n",
      "506 0.2246703803539276\n",
      "507 0.22440651059150696\n",
      "508 0.22414326667785645\n",
      "509 0.22388067841529846\n",
      "510 0.22361873090267181\n",
      "511 0.2233573943376541\n",
      "512 0.2230967879295349\n",
      "513 0.22283673286437988\n",
      "514 0.22257736325263977\n",
      "515 0.22231855988502502\n",
      "516 0.2220604419708252\n",
      "517 0.22180292010307312\n",
      "518 0.22154611349105835\n",
      "519 0.22128984332084656\n",
      "520 0.22103416919708252\n",
      "521 0.2207791954278946\n",
      "522 0.22052472829818726\n",
      "523 0.22027091681957245\n",
      "524 0.22001774609088898\n",
      "525 0.21976518630981445\n",
      "526 0.2195131778717041\n",
      "527 0.21926181018352509\n",
      "528 0.21901100873947144\n",
      "529 0.21876081824302673\n",
      "530 0.21851129829883575\n",
      "531 0.21826229989528656\n",
      "532 0.2180139124393463\n",
      "533 0.21776612102985382\n",
      "534 0.21751892566680908\n",
      "535 0.21727225184440613\n",
      "536 0.21702620387077332\n",
      "537 0.21678072214126587\n",
      "538 0.21653586626052856\n",
      "539 0.21629148721694946\n",
      "540 0.2160477340221405\n",
      "541 0.2158045768737793\n",
      "542 0.21556197106838226\n",
      "543 0.2153199315071106\n",
      "544 0.21507848799228668\n",
      "545 0.21483761072158813\n",
      "546 0.21459725499153137\n",
      "547 0.2143574059009552\n",
      "548 0.21411821246147156\n",
      "549 0.2138795107603073\n",
      "550 0.21364142000675201\n",
      "551 0.21340380609035492\n",
      "552 0.213166743516922\n",
      "553 0.2129303216934204\n",
      "554 0.21269431710243225\n",
      "555 0.21245890855789185\n",
      "556 0.21222400665283203\n",
      "557 0.21198974549770355\n",
      "558 0.2117559015750885\n",
      "559 0.21152269840240479\n",
      "560 0.21128994226455688\n",
      "561 0.21105781197547913\n",
      "562 0.2108260989189148\n",
      "563 0.2105949968099594\n",
      "564 0.21036440134048462\n",
      "565 0.21013426780700684\n",
      "566 0.2099047154188156\n",
      "567 0.2096756100654602\n",
      "568 0.20944708585739136\n",
      "569 0.2092190980911255\n",
      "570 0.20899160206317902\n",
      "571 0.20876459777355194\n",
      "572 0.20853811502456665\n",
      "573 0.2083120495080948\n",
      "574 0.20808660984039307\n",
      "575 0.20786166191101074\n",
      "576 0.20763716101646423\n",
      "577 0.2074132114648819\n",
      "578 0.20718973875045776\n",
      "579 0.20696675777435303\n",
      "580 0.2067442536354065\n",
      "581 0.20652228593826294\n",
      "582 0.20630082488059998\n",
      "583 0.20607972145080566\n",
      "584 0.2058592289686203\n",
      "585 0.20563922822475433\n",
      "586 0.2054196298122406\n",
      "587 0.20520061254501343\n",
      "588 0.20498201251029968\n",
      "589 0.20476385951042175\n",
      "590 0.20454628765583038\n",
      "591 0.20432913303375244\n",
      "592 0.2041124552488327\n",
      "593 0.20389626920223236\n",
      "594 0.20368050038814545\n",
      "595 0.20346525311470032\n",
      "596 0.20325042307376862\n",
      "597 0.2030361294746399\n",
      "598 0.2028222382068634\n",
      "599 0.20260874927043915\n",
      "600 0.20239582657814026\n",
      "601 0.20218336582183838\n",
      "602 0.2019713819026947\n",
      "603 0.20175980031490326\n",
      "604 0.20154866576194763\n",
      "605 0.2013380229473114\n",
      "606 0.20112775266170502\n",
      "607 0.20091800391674042\n",
      "608 0.20070871710777283\n",
      "609 0.20049983263015747\n",
      "610 0.20029141008853912\n",
      "611 0.20008346438407898\n",
      "612 0.1998758614063263\n",
      "613 0.1996687650680542\n",
      "614 0.19946211576461792\n",
      "615 0.19925594329833984\n",
      "616 0.19905012845993042\n",
      "617 0.1988447904586792\n",
      "618 0.1986398547887802\n",
      "619 0.19843539595603943\n",
      "620 0.1982313096523285\n",
      "621 0.19802772998809814\n",
      "622 0.19782456755638123\n",
      "623 0.19762179255485535\n",
      "624 0.1974194049835205\n",
      "625 0.19721749424934387\n",
      "626 0.19701598584651947\n",
      "627 0.19681492447853088\n",
      "628 0.19661428034305573\n",
      "629 0.1964140385389328\n",
      "630 0.1962141990661621\n",
      "631 0.19601480662822723\n",
      "632 0.1958158016204834\n",
      "633 0.1956171989440918\n",
      "634 0.1954190731048584\n",
      "635 0.19522133469581604\n",
      "636 0.19502396881580353\n",
      "637 0.19482696056365967\n",
      "638 0.1946304440498352\n",
      "639 0.19443434476852417\n",
      "640 0.1942385584115982\n",
      "641 0.19404326379299164\n",
      "642 0.19384829699993134\n",
      "643 0.19365373253822327\n",
      "644 0.19345960021018982\n",
      "645 0.1932658702135086\n",
      "646 0.19307251274585724\n",
      "647 0.1928795427083969\n",
      "648 0.19268698990345\n",
      "649 0.19249486923217773\n",
      "650 0.19230307638645172\n",
      "651 0.19211167097091675\n",
      "652 0.191920667886734\n",
      "653 0.1917300969362259\n",
      "654 0.19153982400894165\n",
      "655 0.19134995341300964\n",
      "656 0.19116051495075226\n",
      "657 0.19097140431404114\n",
      "658 0.19078271090984344\n",
      "659 0.1905943751335144\n",
      "660 0.19040638208389282\n",
      "661 0.19021891057491302\n",
      "662 0.19003170728683472\n",
      "663 0.18984484672546387\n",
      "664 0.18965846300125122\n",
      "665 0.18947233259677887\n",
      "666 0.18928664922714233\n",
      "667 0.18910129368305206\n",
      "668 0.18891626596450806\n",
      "669 0.18873172998428345\n",
      "670 0.18854746222496033\n",
      "671 0.18836364150047302\n",
      "672 0.1881800889968872\n",
      "673 0.1879969835281372\n",
      "674 0.18781417608261108\n",
      "675 0.187631756067276\n",
      "676 0.187449648976326\n",
      "677 0.18726800382137299\n",
      "678 0.18708662688732147\n",
      "679 0.18690568208694458\n",
      "680 0.18672502040863037\n",
      "681 0.18654468655586243\n",
      "682 0.1863647699356079\n",
      "683 0.18618521094322205\n",
      "684 0.18600599467754364\n",
      "685 0.1858270913362503\n",
      "686 0.18564853072166443\n",
      "687 0.18547038733959198\n",
      "688 0.18529248237609863\n",
      "689 0.18511497974395752\n",
      "690 0.18493786454200745\n",
      "691 0.18476101756095886\n",
      "692 0.18458455801010132\n",
      "693 0.18440841138362885\n",
      "694 0.1842326521873474\n",
      "695 0.18405720591545105\n",
      "696 0.1838819980621338\n",
      "697 0.18370726704597473\n",
      "698 0.18353289365768433\n",
      "699 0.18335874378681183\n",
      "700 0.18318498134613037\n",
      "701 0.18301156163215637\n",
      "702 0.18283842504024506\n",
      "703 0.1826656609773636\n",
      "704 0.1824932098388672\n",
      "705 0.18232104182243347\n",
      "706 0.182149276137352\n",
      "707 0.1819777488708496\n",
      "708 0.18180668354034424\n",
      "709 0.1816357970237732\n",
      "710 0.18146537244319916\n",
      "711 0.18129506707191467\n",
      "712 0.18112531304359436\n",
      "713 0.18095579743385315\n",
      "714 0.18078657984733582\n",
      "715 0.1806175857782364\n",
      "716 0.1804490089416504\n",
      "717 0.18028084933757782\n",
      "718 0.18011292815208435\n",
      "719 0.17994529008865356\n",
      "720 0.17977789044380188\n",
      "721 0.17961087822914124\n",
      "722 0.17944428324699402\n",
      "723 0.1792779564857483\n",
      "724 0.17911183834075928\n",
      "725 0.17894598841667175\n",
      "726 0.17878058552742004\n",
      "727 0.1786154806613922\n",
      "728 0.1784505844116211\n",
      "729 0.17828604578971863\n",
      "730 0.1781218945980072\n",
      "731 0.17795801162719727\n",
      "732 0.17779433727264404\n",
      "733 0.1776309460401535\n",
      "734 0.17746791243553162\n",
      "735 0.17730532586574554\n",
      "736 0.17714282870292664\n",
      "737 0.17698079347610474\n",
      "738 0.17681892216205597\n",
      "739 0.17665745317935944\n",
      "740 0.17649617791175842\n",
      "741 0.17633521556854248\n",
      "742 0.1761745810508728\n",
      "743 0.17601433396339417\n",
      "744 0.1758541762828827\n",
      "745 0.17569446563720703\n",
      "746 0.17553499341011047\n",
      "747 0.1753758192062378\n",
      "748 0.175216943025589\n",
      "749 0.1750583052635193\n",
      "750 0.17490004003047943\n",
      "751 0.17474201321601868\n",
      "752 0.1745842695236206\n",
      "753 0.1744268387556076\n",
      "754 0.17426961660385132\n",
      "755 0.17411285638809204\n",
      "756 0.17395615577697754\n",
      "757 0.17379985749721527\n",
      "758 0.17364387214183807\n",
      "759 0.17348802089691162\n",
      "760 0.17333254218101501\n",
      "761 0.17317743599414825\n",
      "762 0.1730225682258606\n",
      "763 0.17286792397499084\n",
      "764 0.172713503241539\n",
      "765 0.172559455037117\n",
      "766 0.17240558564662933\n",
      "767 0.17225205898284912\n",
      "768 0.17209884524345398\n",
      "769 0.17194581031799316\n",
      "770 0.17179308831691742\n",
      "771 0.1716405749320984\n",
      "772 0.17148838937282562\n",
      "773 0.1713365912437439\n",
      "774 0.17118488252162933\n",
      "775 0.17103351652622223\n",
      "776 0.17088237404823303\n",
      "777 0.17073146998882294\n",
      "778 0.17058095335960388\n",
      "779 0.17043061554431915\n",
      "780 0.17028063535690308\n",
      "781 0.17013078927993774\n",
      "782 0.16998127102851868\n",
      "783 0.16983197629451752\n",
      "784 0.16968299448490143\n",
      "785 0.16953429579734802\n",
      "786 0.16938582062721252\n",
      "787 0.16923755407333374\n",
      "788 0.1690896600484848\n",
      "789 0.168941929936409\n",
      "790 0.16879448294639587\n",
      "791 0.16864731907844543\n",
      "792 0.16850042343139648\n",
      "793 0.16835376620292664\n",
      "794 0.16820727288722992\n",
      "795 0.16806118190288544\n",
      "796 0.1679152548313141\n",
      "797 0.16776955127716064\n",
      "798 0.16762417554855347\n",
      "799 0.16747906804084778\n",
      "800 0.1673341989517212\n",
      "801 0.16718943417072296\n",
      "802 0.16704508662223816\n",
      "803 0.16690093278884888\n",
      "804 0.1667570173740387\n",
      "805 0.16661332547664642\n",
      "806 0.16646991670131683\n",
      "807 0.16632676124572754\n",
      "808 0.16618378460407257\n",
      "809 0.16604113578796387\n",
      "810 0.16589874029159546\n",
      "811 0.16575655341148376\n",
      "812 0.16561460494995117\n",
      "813 0.16547289490699768\n",
      "814 0.16533148288726807\n",
      "815 0.1651902049779892\n",
      "816 0.1650492250919342\n",
      "817 0.1649084985256195\n",
      "818 0.16476799547672272\n",
      "819 0.16462773084640503\n",
      "820 0.16448765993118286\n",
      "821 0.16434788703918457\n",
      "822 0.16420835256576538\n",
      "823 0.1640690118074417\n",
      "824 0.16392986476421356\n",
      "825 0.16379106044769287\n",
      "826 0.1636524498462677\n",
      "827 0.16351403295993805\n",
      "828 0.1633758842945099\n",
      "829 0.16323798894882202\n",
      "830 0.16310030221939087\n",
      "831 0.16296282410621643\n",
      "832 0.16282552480697632\n",
      "833 0.16268858313560486\n",
      "834 0.16255182027816772\n",
      "835 0.1624152958393097\n",
      "836 0.1622789204120636\n",
      "837 0.1621427834033966\n",
      "838 0.1620069444179535\n",
      "839 0.1618713140487671\n",
      "840 0.1617358922958374\n",
      "841 0.16160079836845398\n",
      "842 0.1614658385515213\n",
      "843 0.1613311469554901\n",
      "844 0.16119658946990967\n",
      "845 0.16106224060058594\n",
      "846 0.16092821955680847\n",
      "847 0.16079427301883698\n",
      "848 0.1606607884168625\n",
      "849 0.16052734851837158\n",
      "850 0.1603940725326538\n",
      "851 0.1602610945701599\n",
      "852 0.1601284146308899\n",
      "853 0.15999582409858704\n",
      "854 0.15986359119415283\n",
      "855 0.1597314178943634\n",
      "856 0.15959954261779785\n",
      "857 0.1594678908586502\n",
      "858 0.1593364179134369\n",
      "859 0.15920519828796387\n",
      "860 0.15907414257526398\n",
      "861 0.1589432954788208\n",
      "862 0.15881270170211792\n",
      "863 0.15868237614631653\n",
      "864 0.1585521548986435\n",
      "865 0.15842223167419434\n",
      "866 0.1582925021648407\n",
      "867 0.1581629514694214\n",
      "868 0.15803351998329163\n",
      "869 0.15790453553199768\n",
      "870 0.15777559578418732\n",
      "871 0.15764693915843964\n",
      "872 0.1575183868408203\n",
      "873 0.1573900580406189\n",
      "874 0.15726205706596375\n",
      "875 0.15713420510292053\n",
      "876 0.15700650215148926\n",
      "877 0.15687903761863708\n",
      "878 0.15675173699855804\n",
      "879 0.1566247045993805\n",
      "880 0.15649789571762085\n",
      "881 0.15637126564979553\n",
      "882 0.15624475479125977\n",
      "883 0.1561184674501419\n",
      "884 0.15599247813224792\n",
      "885 0.1558665782213211\n",
      "886 0.15574094653129578\n",
      "887 0.15561559796333313\n",
      "888 0.15549032390117645\n",
      "889 0.1553652286529541\n",
      "890 0.15524038672447205\n",
      "891 0.1551157534122467\n",
      "892 0.1549912989139557\n",
      "893 0.154867023229599\n",
      "894 0.1547430455684662\n",
      "895 0.15461912751197815\n",
      "896 0.1544954925775528\n",
      "897 0.15437200665473938\n",
      "898 0.1542486995458603\n",
      "899 0.15412569046020508\n",
      "900 0.15400275588035583\n",
      "901 0.15388010442256927\n",
      "902 0.15375763177871704\n",
      "903 0.15363526344299316\n",
      "904 0.15351314842700958\n",
      "905 0.1533913016319275\n",
      "906 0.15326949954032898\n",
      "907 0.15314799547195435\n",
      "908 0.15302665531635284\n",
      "909 0.15290549397468567\n",
      "910 0.15278460085391998\n",
      "911 0.15266373753547668\n",
      "912 0.15254318714141846\n",
      "913 0.15242283046245575\n",
      "914 0.1523025780916214\n",
      "915 0.15218248963356018\n",
      "916 0.15206262469291687\n",
      "917 0.15194305777549744\n",
      "918 0.15182363986968994\n",
      "919 0.15170422196388245\n",
      "920 0.15158513188362122\n",
      "921 0.15146632492542267\n",
      "922 0.15134753286838531\n",
      "923 0.15122903883457184\n",
      "924 0.15111058950424194\n",
      "925 0.15099242329597473\n",
      "926 0.15087440609931946\n",
      "927 0.15075653791427612\n",
      "928 0.15063896775245667\n",
      "929 0.15052145719528198\n",
      "930 0.15040424466133118\n",
      "931 0.15028715133666992\n",
      "932 0.1501702070236206\n",
      "933 0.1500534564256668\n",
      "934 0.14993689954280853\n",
      "935 0.14982056617736816\n",
      "936 0.149704247713089\n",
      "937 0.1495882272720337\n",
      "938 0.1494724452495575\n",
      "939 0.14935675263404846\n",
      "940 0.14924119412899017\n",
      "941 0.14912593364715576\n",
      "942 0.14901071786880493\n",
      "943 0.1488957703113556\n",
      "944 0.14878103137016296\n",
      "945 0.1486663818359375\n",
      "946 0.14855194091796875\n",
      "947 0.14843757450580597\n",
      "948 0.14832355082035065\n",
      "949 0.14820954203605652\n",
      "950 0.14809586107730865\n",
      "951 0.14798223972320557\n",
      "952 0.1478688269853592\n",
      "953 0.14775556325912476\n",
      "954 0.14764255285263062\n",
      "955 0.14752960205078125\n",
      "956 0.1474168747663498\n",
      "957 0.14730434119701385\n",
      "958 0.14719195663928986\n",
      "959 0.14707975089550018\n",
      "960 0.14696764945983887\n",
      "961 0.14685571193695068\n",
      "962 0.14674405753612518\n",
      "963 0.14663240313529968\n",
      "964 0.14652101695537567\n",
      "965 0.1464097946882248\n",
      "966 0.14629873633384705\n",
      "967 0.14618784189224243\n",
      "968 0.14607718586921692\n",
      "969 0.1459665596485138\n",
      "970 0.14585621654987335\n",
      "971 0.14574599266052246\n",
      "972 0.1456359475851059\n",
      "973 0.14552602171897888\n",
      "974 0.145416259765625\n",
      "975 0.14530661702156067\n",
      "976 0.14519727230072021\n",
      "977 0.14508794248104095\n",
      "978 0.1449788510799408\n",
      "979 0.14486996829509735\n",
      "980 0.14476123452186584\n",
      "981 0.1446525752544403\n",
      "982 0.1445440649986267\n",
      "983 0.14443576335906982\n",
      "984 0.14432762563228607\n",
      "985 0.14421960711479187\n",
      "986 0.14411179721355438\n",
      "987 0.14400415122509003\n",
      "988 0.14389668405056\n",
      "989 0.14378927648067474\n",
      "990 0.14368218183517456\n",
      "991 0.14357508718967438\n",
      "992 0.14346832036972046\n",
      "993 0.14336150884628296\n",
      "994 0.14325496554374695\n",
      "995 0.14314855635166168\n",
      "996 0.14304229617118835\n",
      "997 0.14293621480464935\n",
      "998 0.14283017814159393\n",
      "999 0.14272446930408478\n",
      "1000 0.14261874556541443\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # forward\n",
    "    logits = model(X_t)\n",
    "    loss = criterion(logits, Y_t)\n",
    "\n",
    "    # backward + update\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print(epoch+1, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2f1bc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A entrada: [0. 0.], tem output: [0.]\n",
      "A entrada: [0. 1.], tem output: [0.]\n",
      "A entrada: [1. 0.], tem output: [0.]\n",
      "A entrada: [1. 1.], tem output: [1.]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for value in X_t:\n",
    "\n",
    "        logits = model(value)\n",
    "        preds = step(logits)\n",
    "\n",
    "        # Passa o tensor preds para a cpu, e pega o campo de valor dela.\n",
    "        print(\"A entrada: \" + str (value.cpu().numpy()) + \", tem output: \" + str(preds.cpu().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
